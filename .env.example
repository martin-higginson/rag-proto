# Git Repository Configuration
GITLAB_TOKEN=your_gitlab_token_here
GITLAB_REPO_URL=https://gitlab.com/your-username/your-repo.git
GITLAB_BRANCH=main
KB_FOLDER=knowledge-base

# RAG Configuration
MODEL=llama3.2
DB_NAME=vector_db
USE_OPENAI_EMBEDDINGS=false
OPENAI_API_KEY=your_openai_api_key_here
CHUNK_SIZE=2000
CHUNK_OVERLAP=500
RETRIEVER_K=25
TEMPERATURE=0.7
FORCE_REFRESH_DB=false

# File Patterns (JSON format)
# FILE_PATTERNS={"cs":"**/*.cs","md":"**/*.md","csproj":"**/*.csproj","sln":"**/*.sln"}

# Excluded Folders (comma-separated)
# EXCLUDED_FOLDERS=.git,bin,obj,packages,node_modules,.idea,NmsGateway.Tests

# Prompt (Defaulted in code)
# PROMPT_TEMPLATE="You are a helpful assistant specializing in your knowledge base.\n\nWhen answering:\n✓ Be accurate and cite sources from the knowledge base\n✓ Use code examples when helpful\n✓ Explain technical concepts clearly\n✗ Don't guess if the information isn't in the context\n✗ Don't provide outdated or speculative information\n\nContext: {context}\n\nQuestion: {question}\n\nAnswer:"


# Embeddings true openai false huggunface deafaults to false
# USE_OPENAI_EMBEDDINGS=false

# Server Configuration
SERVER_PORT=7860
SERVER_HOST=0.0.0.0
OPEN_BROWSER=false
SHARE_GRADIO=false

# Logging
LOG_LEVEL=INFO

# Ollama Configuration (for docker-compose)
OLLAMA_BASE_URL=http://ollama:11434
